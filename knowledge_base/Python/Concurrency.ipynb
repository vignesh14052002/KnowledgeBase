{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async programming in python with asyncio\n",
    "\n",
    "## Table of Contents\n",
    "- Threading Vs Multiprocessing Vs Asyncio\n",
    "- Understanding `async` and `await`\n",
    "- Profiling\n",
    "- Asyncio patterns\n",
    "  - `asyncio.gather` is enough for most cases\n",
    "  - get response as soon as they complete\n",
    "  - cancel tasks while executing\n",
    "  - prevent bubbling up async/await to parent functions\n",
    "  - asyncio cheat sheet\n",
    "- Excercise\n",
    "  - Optimize the following code snippets\n",
    "    - Executing Steps and logging to server\n",
    "    - Performing multi stage async calls\n",
    "    - Concurrency with caching\n",
    "- Side effects\n",
    "  - facing rate limit errors from recipient\n",
    "    - to avoid\n",
    "      - use semaphores to limit requests\n",
    "      - use batch requests to reduce request count\n",
    "      - use debouncing and throttling\n",
    "    - to handle\n",
    "      - use a retry mechanism\n",
    "- resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading vs Multiprocessing vs Asyncio \n",
    "\n",
    "[Understanding Process, Threads and Context Switching](https://dev.to/coderatul/threading-vs-asyncio-vs-multiprocessing-10ed)\n",
    "\n",
    "- CPU Bound (parallelism)\n",
    "  - multiprocessing\n",
    "    - distributes tasks to cores\n",
    "    - starting and stopping process is expensive\n",
    "\n",
    "- IO Bound (pseudo parallelism)\n",
    "  - threading\n",
    "    - starting and stopping threads is expensive\n",
    "    - low control over context switching\n",
    "    - [prone to race conditions](https://dev.to/coderatul/race-condition-in-pythons-threading-3o4g)\n",
    "  - asyncio\n",
    "    - high control over context switching\n",
    "  \n",
    "- [Example Code](https://stackoverflow.com/a/74327302)\n",
    "\n",
    "> **Tip** : Always prefer asyncio over threading for IO bound tasks in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding async and await\n",
    "\n",
    "`async` will mark the function as coroutine\n",
    "\n",
    "`await` will be used on coroutine for context-switching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object aget_data at 0x00000188250F7C40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def aget_data()->str:\n",
    "    print(\"Fetching data...\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Fetched data\")\n",
    "    return \"data\"\n",
    "\n",
    "aget_data() # gives back coroutine instead of executing\n",
    "# await aget_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling\n",
    "\n",
    "Premature optimization is the root of all evil. If it feels your application in slow, picking up a random module and optimizing it might not be the best idea.\n",
    "\n",
    "You need to know which part of your code causes the major time lag and fix it.\n",
    "Profiling helps you to understand your code better\n",
    "\n",
    "In python, profiling comes for free as builtins\n",
    "- `cProfile` and `pstats` will help profile your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import Profile\n",
    "from pstats import Stats\n",
    "import time\n",
    "\n",
    "def util():\n",
    "    time.sleep(0.1)\n",
    "\n",
    "def my_expensive_code():\n",
    "    for _ in range(30):\n",
    "        util()\n",
    "\n",
    "with Profile() as profile:\n",
    "    my_expensive_code()\n",
    "stats = Stats(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         63 function calls in 3.019 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    3.019    3.019 C:\\Users\\vignesh.arivazhagan\\AppData\\Local\\Temp\\ipykernel_5368\\3965047745.py:8(my_expensive_code)\n",
      "       30    0.000    0.000    3.019    0.101 C:\\Users\\vignesh.arivazhagan\\AppData\\Local\\Temp\\ipykernel_5368\\3965047745.py:5(util)\n",
      "       30    3.018    0.101    3.018    0.101 {built-in method time.sleep}\n",
      "        1    0.000    0.000    0.000    0.000 C:\\Users\\vignesh.arivazhagan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\cProfile.py:117(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x188262d0090>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.sort_stats(\"cumulative\").print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making an async request\n",
    "`requests` is a popular built in for synchronous requests\n",
    "\n",
    "`aiohttp` can be used as a replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "\n",
    "async def afetch(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.json()\n",
    "        \n",
    "url = \"https://api.sampleapis.com/codingresources/codingResources\"\n",
    "\n",
    "await afetch(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asyncio Patterns\n",
    "List of common concurrency usecases with `asyncio`\n",
    "\n",
    "### `asyncio.gather` is enough for most cases\n",
    "A common usecase of concurrency is to make a bunch of requests, we can achieve it using `asyncio.gather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 3...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 2...\n",
      "Fetched data for param = 1\n",
      "Fetched data for param = 2\n",
      "Fetched data for param = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data for param = 3', 'Data for param = 1', 'Data for param = 2']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is Preferred to add Prefix 'a' to all async functions for readablity\n",
    "async def aget_data(param)->str:\n",
    "    print(f\"Fetching data for {param = }...\")\n",
    "    await asyncio.sleep(param)\n",
    "    print(f\"Fetched data for {param = }\")\n",
    "    return f\"Data for {param = }\"\n",
    "\n",
    "request_params = [3,1,2]\n",
    "tasks = [aget_data(param) for param in request_params]\n",
    "\n",
    "await asyncio.gather(*tasks) # Order is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get response as soon as they complete\n",
    "this can be used for progress indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vignesh.arivazhagan\\AppData\\Local\\Temp\\ipykernel_5368\\262447371.py:4: RuntimeWarning: coroutine 'as_completed.<locals>._wait_for_one' was never awaited\n",
      "  for task in asyncio.as_completed(tasks):\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 2...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 3...\n",
      "Fetched data for param = 1\n",
      "Data for param = 1\n",
      "Fetched data for param = 2\n",
      "Data for param = 2\n",
      "Fetched data for param = 3\n",
      "Data for param = 3\n"
     ]
    }
   ],
   "source": [
    "request_params = [3,1,2]\n",
    "tasks = [aget_data(param) for param in request_params]\n",
    "\n",
    "for task in asyncio.as_completed(tasks):\n",
    "    result = await task\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancel tasks while executing\n",
    "lets say you want to cancel already made request, when user clicks cancel button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 3...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 2...\n",
      "Fetched data for param = 1\n"
     ]
    }
   ],
   "source": [
    "request_params = [3,1,2]\n",
    "tasks = [asyncio.create_task(aget_data(param)) for param in request_params]\n",
    "\n",
    "def is_cancel_button_pressed()->bool:\n",
    "    return True\n",
    "\n",
    "try:\n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        result = await task\n",
    "        \n",
    "        if is_cancel_button_pressed():\n",
    "            for task in tasks:\n",
    "                if not task.done():\n",
    "                    task.cancel()\n",
    "                    \n",
    "except asyncio.CancelledError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevent bubbling up async/await to parent functions\n",
    "lets say you are making a deeply nested function as async, then you need to make all its parent functions from the callstack async and need to add await statements to all of the calls, to overcome this we can use `asyncio.run` to make it synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['result for 0', 'result for 1', 'result for 2']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply() # Jupyter notebook is already in event loop\n",
    "\n",
    "async def autil(i):\n",
    "    await asyncio.sleep(1)\n",
    "    return f\"result for {i}\"\n",
    "\n",
    "def deeply_nested_function():\n",
    "    tasks = [autil(i) for i in range(3)]\n",
    "    return asyncio.run(asyncio.gather(*tasks))\n",
    "\n",
    "# can be executed without await\n",
    "deeply_nested_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asyncio cheat sheet\n",
    "The above techniques are some of most common usage patterns\n",
    "\n",
    "but `asyncio` is capable of doing a lot more, refer [asyncio cheatsheet](https://marvelous-writer-6152.kit.com/d29b7d8dfb) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises\n",
    "Now you know the techniques to do different tasks, lets test our understanding with few problem statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify a potential optimization in the following codes\n",
    "\n",
    "#### 1. Executing steps and storing logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 3...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 2...\n",
      "Fetched data for param = 1\n",
      "Fetched data for param = 2\n",
      "Fetched data for param = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data for param = 3', 'Data for param = 1', 'Data for param = 2']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def alog_to_cloud(data:str)->None:\n",
    "    # Make request to logging server\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "async def execute_step(param)->str:\n",
    "    await alog_to_cloud(f\"Executing Step with {param = }...\")\n",
    "    result = await aget_data(param)\n",
    "    await alog_to_cloud(f\"Executed Step with {param = }\")\n",
    "    return result\n",
    "\n",
    "# Main program\n",
    "\n",
    "steps = [3,1,2]\n",
    "tasks = [execute_step(param) for param in steps]\n",
    "await asyncio.gather(*tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution : Don't wait for tasks you don't need to\n",
    "we are not going to process the response of logging request, so it is not need to wait there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 3...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 2...\n",
      "Fetched data for param = 1\n",
      "Fetched data for param = 2\n",
      "Fetched data for param = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data for param = 3', 'Data for param = 1', 'Data for param = 2']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "async def alog_to_cloud(data:str)->None:\n",
    "    # Make request to logging server\n",
    "    asyncio.create_task(asyncio.sleep(1)) # will trigger request\n",
    "\n",
    "async def execute_step(param)->str:\n",
    "    await alog_to_cloud(f\"Executing Step with {param = }...\")\n",
    "    result = await aget_data(param)\n",
    "    await alog_to_cloud(f\"Executed Step with {param = }\")\n",
    "    return result\n",
    "\n",
    "# Main program\n",
    "\n",
    "steps = [3,1,2]\n",
    "tasks = [execute_step(param) for param in steps]\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Performing multi stage async calls\n",
    "While developing solution, not all requests can be made concurrent, because the response of one can be an input of another\n",
    "\n",
    "try to come up with a more optimal way for the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 3...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 2...\n",
      "Fetched data for param = 1\n",
      "Fetched data for param = 2\n",
      "Fetched data for param = 3\n",
      "Processing Data for param = 3...\n",
      "Processing Data for param = 1...\n",
      "Processing Data for param = 2...\n",
      "Processing Data for param = 3...\n",
      "Processing Data for param = 1...\n",
      "Processing Data for param = 2...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Processed Data for param = 3',\n",
       " 'Processed Data for param = 1',\n",
       " 'Processed Data for param = 2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def aprocess_data(execution_time,data):\n",
    "    print(f\"Processing {data}...\")\n",
    "    await asyncio.sleep(execution_time)\n",
    "    print(f\"Processing {data}...\")\n",
    "    return f\"Processed {data}\"\n",
    "\n",
    "params = [3,1,2]\n",
    "processing_time = [1,1,3]\n",
    "\n",
    "data_fetching_tasks = [aget_data(param) for param in params]\n",
    "results = await asyncio.gather(*data_fetching_tasks)\n",
    "\n",
    "data_processing_tasks = [aprocess_data(exec_time,data) for exec_time,data in zip(processing_time,results)]\n",
    "processed_results = await asyncio.gather(*data_processing_tasks)\n",
    "processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution : Again ðŸ¤¦â€â™‚ï¸, Don't wait when you don't need to\n",
    "the 2nd task with fetching time 1 don't need to wait for all other fetch to complete to get processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for param = 3...\n",
      "Fetching data for param = 1...\n",
      "Fetching data for param = 2...\n",
      "Fetched data for param = 1\n",
      "Processing Data for param = 1...\n",
      "Fetched data for param = 2\n",
      "Processing Data for param = 2...\n",
      "Processing Data for param = 1...\n",
      "Fetched data for param = 3\n",
      "Processing Data for param = 3...\n",
      "Processing Data for param = 3...\n",
      "Processing Data for param = 2...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Processed Data for param = 3',\n",
       " 'Processed Data for param = 1',\n",
       " 'Processed Data for param = 2']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def aget_processed_data(execution_time,param):\n",
    "    result = await aget_data(param)\n",
    "    return await aprocess_data(execution_time,result)\n",
    "\n",
    "params = [3,1,2]\n",
    "processing_time = [1,1,3]\n",
    "\n",
    "tasks = [aget_processed_data(exec_time,param) for exec_time,param in zip(processing_time,params)]\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Concurrency with caching on pure APIs\n",
    "pure functions are functions which will always give same output for same inputs\n",
    "\n",
    "while executing things sequencially, to prevent recomputing, we will store input and output in a hashmap\n",
    "\n",
    "but for pure api's (api which gives same result for same params), how can we balance concurrency and caching?\n",
    "\n",
    "can you bring down compute cost in the following code without compromising time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results = [9, 4, 1, 9, 25, 4, 1, 1], compute_cost = 8\n"
     ]
    }
   ],
   "source": [
    "compute_cost = 0\n",
    "\n",
    "async def aget_result(num:int)->int:\n",
    "    global compute_cost\n",
    "    compute_cost+=1\n",
    "    await asyncio.sleep(1)\n",
    "    return num*num\n",
    "\n",
    "nums = [3,2,1,3,5,2,1,1]\n",
    "\n",
    "tasks = [aget_result(num) for num in nums]\n",
    "\n",
    "results = await asyncio.gather(*tasks)\n",
    "print(f\"{results = }, {compute_cost = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results = [9, 4, 1, 9, 25, 4, 1, 1], compute_cost = 4\n"
     ]
    }
   ],
   "source": [
    "# Compromising time with compute_cost\n",
    "\n",
    "compute_cost = 0\n",
    "cache = {}\n",
    "results = []\n",
    "\n",
    "for num in nums:\n",
    "    if num not in cache:\n",
    "        result = await aget_result(num)\n",
    "        cache[num] = result\n",
    "    else:\n",
    "        result = cache[num]\n",
    "    results.append(result)\n",
    "\n",
    "print(f\"{results = }, {compute_cost = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution: Collect unique tasks, compute and map to input order\n",
    "we can maintain a hashmap with key as unique num and value as their task\n",
    "then iterate through nums, get result from map, frame results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results = [9, 4, 1, 9, 25, 4, 1, 1], compute_cost = 4\n"
     ]
    }
   ],
   "source": [
    "compute_cost = 0\n",
    "\n",
    "unique_nums = list(set(nums))\n",
    "unique_task_map = {num: asyncio.create_task(aget_result(num)) for num in unique_nums}\n",
    "\n",
    "await asyncio.gather(*unique_task_map.values())\n",
    "\n",
    "# Map results back to the original input order\n",
    "results = [unique_task_map[num].result() for num in nums]\n",
    "print(f\"{results = }, {compute_cost = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side Effects\n",
    "now you know how to optimize performance by making concurrent requests. In ideal scenario it should work great, but not all API that we interact will have the capablity to process such huge demand (if you are making 1000s of concurrent requests), lets discuss how to handle if you got limited by APIs capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facing Rate limit errors from recipient\n",
    "to prevent DDOS attacks, servers which exposes API's will usually throw ratelimit error if high requests recieved from single source in a short span of time\n",
    "\n",
    "there are few ways to avoid this from happening and handle this if happened\n",
    "### To avoid\n",
    "#### 1. Use semaphores to limit requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2, 2, 1, 2]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_requests = 0\n",
    "semaphore = asyncio.Semaphore(2)\n",
    "\n",
    "async def api_with_less_capacity(param):\n",
    "    global active_requests\n",
    "    active_requests+=1\n",
    "    if active_requests>2:\n",
    "        raise Exception(\"Can't process more than 2 active requests\")\n",
    "    await asyncio.sleep(param)\n",
    "    active_requests-=1\n",
    "    return param\n",
    "\n",
    "async def acall_api(param):\n",
    "    async with semaphore:\n",
    "        return await api_with_less_capacity(param)\n",
    "    \n",
    "params = [3,1,2,2,1,2]\n",
    "\n",
    "tasks = [acall_api(param) for param in params]\n",
    "\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use batch requests\n",
    "If the recipient accepts a batch of inputs, it is always recommended to use it instead of making individual concurrent requests\n",
    "\n",
    "#### 3. Use debouncing and throttling\n",
    "debouncing - cancel deffered previous request if a new request comes within timeframe\n",
    "throttling - dont allow further requests if last request time is below threshold\n",
    "\n",
    "[visualization](https://web.archive.org/web/20220117092326/http://demo.nimius.net/debounce_throttle/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function called with index = 0 param = 1\n",
      "Function called with index = 2 param = 3\n",
      "Function called with index = 3 param = 4\n",
      "Function called with index = 4 param = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, None, 3, 4, 5]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "def debounce(timeout: float):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            if wrapper.task:\n",
    "                wrapper.task.cancel()\n",
    "            wrapper.task = asyncio.create_task(wrapper._debounced_call(func, *args, **kwargs))\n",
    "            \n",
    "        async def _debounced_call(func, *args, **kwargs):\n",
    "            await asyncio.sleep(timeout)\n",
    "            return await func(*args, **kwargs)\n",
    "        \n",
    "        wrapper.task = None\n",
    "        wrapper._debounced_call = _debounced_call\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def throttle(wait_time):\n",
    "    def decorator(function):\n",
    "        @functools.wraps(function)\n",
    "        async def throttled(*args, **kwargs):\n",
    "            if time.time() - throttled._last_time_called >= wait_time:\n",
    "                throttled._last_time_called = time.time()\n",
    "                return await function(*args, **kwargs)\n",
    "\n",
    "        throttled._last_time_called = 0\n",
    "        return throttled\n",
    "\n",
    "    return decorator\n",
    "\n",
    "@throttle(0.9)\n",
    "async def high_fequency_function(index,param):\n",
    "    print(f\"Function called with {index = } {param = }\")\n",
    "    return param\n",
    "\n",
    "async def wait_and_call(index,param):\n",
    "    await asyncio.sleep(param)\n",
    "    return await high_fequency_function(index,param)\n",
    "\n",
    "params  = [1,1,3,4,5]\n",
    "tasks = [wait_and_call(i,param) for i,param in enumerate(params)]\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To handle\n",
    "retry after a delay, but remember to set max_retries, so that you won't retry forever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying after 1 seconds...\n",
      "Retrying after 1 seconds...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 3, 4, 5]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def retry_on_exception(max_retries: int, delay: float):\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        async def wrapper(*args, **kwargs):\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    return await func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"Retrying after {delay} seconds...\")\n",
    "                        await asyncio.sleep(delay)\n",
    "                    else:\n",
    "                        raise e\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@retry_on_exception(max_retries=3,delay=1)\n",
    "async def api_call(param):\n",
    "    if random.random() < 0.2:\n",
    "        raise Exception(\"Can't process\")\n",
    "    await asyncio.sleep(1)\n",
    "    return param\n",
    "\n",
    "params  = [1,1,3,4,5]\n",
    "tasks = [api_call(param) for param in params]\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "- [SuperFastPython](https://superfastpython.com/)\n",
    "- [PythonSpeed](https://pythonspeed.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
